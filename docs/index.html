<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>SELF-INSTRUCT â€” Step 1: Instruction Generation</title>
  <style>
    :root {
      --bg: #0b0f14; --panel: #0f1520; --ink: #e6edf3; --muted:#9fb3c8; --acc:#73caff; --hl:#243447;
      --ok:#7bd88f; --warn:#ffd479; --err:#ff6b6b;
    }
    html, body {margin:0; padding:0; background:var(--bg); color:var(--ink); font:16px/1.6 system-ui, -apple-system, Segoe UI, Roboto, Ubuntu, Cantarell, Noto Sans, Helvetica, Arial, Apple Color Emoji, Segoe UI Emoji;}
    main {max-width: 980px; margin: 48px auto 96px; padding: 0 20px;}
    header h1 {font-size: 2.2rem; margin: 0 0 8px;}
    header p {color: var(--muted); margin: 0 0 24px;}
    .panel {background: var(--panel); border: 1px solid #1f2937; border-radius: 16px; padding: 20px; box-shadow: 0 8px 30px rgba(0,0,0,.25);}    
    h2 {font-size: 1.4rem; border-left: 4px solid var(--acc); padding-left: 10px; margin-top: 28px;}
    h3 {font-size: 1.1rem; color: var(--muted); margin-top: 22px;}
    code, pre {font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace;}
    pre {background: #0c111b; border: 1px solid #1f2937; border-radius: 12px; padding: 14px; overflow: auto;}
    .grid {display: grid; gap: 12px; grid-template-columns: repeat(auto-fit,minmax(240px,1fr));}
    .tag {display:inline-block; padding: 2px 8px; border-radius: 999px; border:1px solid #1f2937; background:#0c111b; color: var(--muted); font-size: .85rem;}
    .callout {border-left: 4px solid var(--acc); padding: 12px 14px; background: #0c111b; border-radius: 8px;}
    table {width: 100%; border-collapse: collapse; background: #0c111b; border-radius: 12px; overflow:hidden;}
    th, td {padding: 10px 12px; border-bottom: 1px solid #1f2937; text-align: left;}
    th {color: var(--muted); background:#0b1220;}
    tr:last-child td {border-bottom: 0;}
    a {color: var(--acc); text-decoration: none;}
    a:hover {text-decoration: underline;}
    .small {font-size:.92rem; color:var(--muted)}
  </style>
</head>
<body>
  <main>
    <header>
      <h1>SELF-INSTRUCT â€” Step 1: Instruction Generation</h1>
      <p class="small">Project: <strong>self-instruct-gpt4mini</strong> â€¢ Author: Dimitris Markopoulos â€¢ Date: 2025â€‘10â€‘15</p>
      <div class="panel">
        <p><strong>Goal.</strong> Expand from a small human-written nucleus of 175 tasks to a large, diverse set of synthetic <em>instructions</em> that look and read like human prompts. This step <em>does not</em> create answers; it only invents new tasks for later stages.</p>
        <div class="grid" style="margin-top:8px">
          <div><span class="tag">Input: 175 seed instructions</span></div>
          <div><span class="tag">Output: synthetic instructions (text only)</span></div>
          <div><span class="tag">Model: GPT-4-mini (API)</span></div>
          <div><span class="tag">Budget target: &lt; $100 (full pipeline)</span></div>
        </div>
      </div>
    </header>

    <section>
      <h2>Concept</h2>
      <p>Provide the model with a few high-quality seed instructions as <em>in-context demonstrations</em> and prompt it to continue the list with new, plausible tasks. Repeat to accumulate thousands of candidates. This bootstraps instruction diversity without additional manual authoring.</p>
    </section>

    <section>
      <h2>Inputs</h2>
      <ul>
        <li><code>data/seed_tasks.jsonl</code> â€” 175 human-written seeds (Apache-2.0).</li>
        <li>Sampler that draws <code>k</code> seeds per batch (default <code>k=8</code>, e.g., 6 human + 2 modelâ€‘generated in later rounds).</li>
      </ul>
    </section>

    <section>
      <h2>Prompt Template</h2>
      <p>Minimal list-continuation prompt (adapted to our repo):</p>
      <pre><code>Come up with a series of tasks:

Task 1. &lt;seed instruction A&gt;
Task 2. &lt;seed instruction B&gt;
Task 3. &lt;seed instruction C&gt;
Task 4. &lt;seed instruction D&gt;
Task 5. &lt;seed instruction E&gt;
Task 6. &lt;seed instruction F&gt;
Task 7. &lt;seed instruction G&gt;
Task 8. &lt;seed instruction H&gt;
Task 9.
</code></pre>
      <p>The model continues until tokens are exceeded (hyperparameter, research uses token threshold) or it decides to stop or reaches 16 items. The constraints are purposely lax to maximize the models "creativity". We then parse the continuation into standalone instructions.</p>
    </section>

    <section>
      <h2>Algorithm</h2>
      <ol>
        <li>Sample <code>8</code> distinct seed instructions (6 from the human curated set (size 175) and 2 from the generated set).</li>
        <li>
            Render prompt (f-string input + instructions) and call the API with mild creativity.
            <div style="margin-left:20px;">
              <p><strong>Hyperparameters:</strong></p>
              <ul style="margin-left:20px;">
                <li><code>temperature = 0.8</code> â€” controls the model's randomness, i.e., how freely it may branch off-topic.</li>
                <li><code>top_p = 0.9</code> â€” restricts token sampling to the top 90% probability mass, keeping outputs coherent.</li>
                <li><code>max_tokens = 1024</code> â€” allows the model to produce multiple new task instructions per call.</li>
              </ul>
            </div>
          </li>
        </p>

        <li>Parse the generated output and grab new data!</li>
        <li>
            Filter and postprocess generated instructions before adding them to the task pool.
            <div style="margin-left:20px;">
                </p>
              <ul style="margin-left:20px;">
                <li><strong>Similarity filter:</strong> Add a new instruction only if its ROUGE-L or embedding similarity with existing tasks is below <code>0.7</code> to maintain diversity.</li>
                <li><strong>Keyword filter:</strong> Remove tasks mentioning unsupported modalities such as <em>image</em>, <em>picture</em>, or <em>graph</em>.</li>
                <li><strong>Length filter:</strong> Discard instructions that are too short (<code>&lt;5</code> words) or too long (<code>&gt;50</code> words).</li>
                <li><strong>Duplicate cleanup:</strong> Exclude instances with identical inputs or conflicting outputs.</li>
              </ul>
            </div>
          </li>
          <p>
          
        <li>Repeat <code>N</code> batches until target count reached (depends on my budget).</li>
      </ol>

      <p><em>Note for step 4: I diverge from the original research paper; I prefer dumping all generated responses first and then performing post-processing.</em></p>
    </section>

    <section>
        <h2>Outputs</h2>
        <table>
          <thead>
            <tr><th>Artifact</th><th>Description</th><th>Location</th></tr>
          </thead>
          <tbody>
            <tr><td><code>generated_instructions.jsonl</code></td><td>Raw synthetic instructions (unlabeled)</td><td><code>data/generated_instructions.jsonl</code></td></tr>
          </tbody>
        </table>
      </section>
  
    <section id="notebooks" style="margin: 3rem 0;">
        <h2 style="text-align:center; font-weight:600; margin-bottom:1rem;"></h2>
      
        <div style="
            border: 2px solid #e0e0e0;
            border-radius: 16px;
            overflow: hidden;
            box-shadow: 0 4px 20px rgba(0,0,0,0.1);
            max-width: 1100px;
            margin: auto;
        ">
          <iframe
            src="https://nbviewer.org/github/dimitris-markopoulos/self-instruct-gpt4mini/blob/main/notebooks/algorithm_output_example.ipynb"
            width="100%"
            height="1000"
            frameborder="0"
            style="border:none;">
          </iframe>
        </div>
      
        <p style="text-align:center; margin-top:1rem;">
          <a href="https://github.com/dimitris-markopoulos/self-instruct-gpt4mini/"
             target="_blank"
             rel="noopener noreferrer"
             style="text-decoration:none; font-weight:500;">
            ðŸ”— View all code on GitHub â†’
          </a>
        </p>
      </section>
      

    <section>
      <h2>Reference Implementation (Python)</h2>
      <pre><code>
#==================================
# STEP 1 : INSTRUCTION GENERATION
#==================================
import random
import openai
import json
from pathlib import Path
import os
from dotenv import load_dotenv
import yaml
import re

# Load API KEY
load_dotenv("secrets.env") # store secret
with open("config.yaml") as f:
    raw_yaml = f.read()
    expanded_yaml = os.path.expandvars(raw_yaml) # Contains secret
    config = yaml.safe_load(expanded_yaml)
openai.api_key = config["openai"]["api_key"] # Configure the OpenAI client

# Download the 175 human-written tasks
with open("data/seed_tasks.jsonl") as f:
    seed_tasks = [json.loads(line) for line in f]

##
def grab_subsample():
    """
    Pulls 6 human-written instructions and 2 LLM instructions. 
    Initalizes with 8 human-written instructions.
    """
    with open("data/generated_tasks.jsonl") as f:
        sampled_llm_tasks = [json.loads(line) for line in f]
    
    if not sampled_llm_tasks: 
        # intialize to all human-written instructions if no generated responses exist
        return random.sample(seed_tasks, 8)
    
    llm_sample = random.sample(sampled_llm_tasks, 2)
    human_sample = random.sample(seed_tasks, 6)

    return llm_sample + human_sample

##
def create_prompt(instruction_sample : list) -> str:
    """
    Render the instruction-generation prompt (using Table 5 from SELF-INSTRUCT).
    """
    header = "Come up with a series of tasks:\n\n"
    lines = []
    for i, task in enumerate(instruction_sample):
        line = f'Task {i+1}: {task["instruction"].strip(" ")}'
        lines.append(line)
        if i == 7: # add last section (empty); for LLM to fill in
            lines.append(f'Task {i+2}:')
    return "\n".join(lines)

##
def generate_instructions(prompt: str, model="gpt-4o-mini") -> str:
    """
    Query OpenAI api to generate new task instructions.
    """
    resp = openai.chat.completions.create(
        model=config["openai"]["model"],
        messages=[ 
            # had to include role because model was being too helpful and did not continue list
            # this gave it further direction - original research did not do this
            {"role": "system", "content": (
                "Continue the numbered list of tasks below. "
                "Write 3 to 8 new Task entries that follow the same style. "
                "Do not explain, comment, or ask for clarification."
            )},
            {"role": "user", "content": prompt}
        ],
        temperature=0.7,
        top_p=0.5,
        max_tokens=1024
    )
    return resp.choices[0].message.content

##
def parse_instructions(text: str) -> list:
    """
    Parse raw model output (continuation of 'Task 9: ...') into a list of clean instruction dicts.
    """
    if not text.strip().startswith("Task"): # prepend "Task 9:" if model didn't include it
        text = "Task 9: " + text.strip()
    matches = re.findall(r"Task\s*\d+:\s*(.+?)(?=\s*Task\s*\d+:|$)", text, flags=re.S) # find all task blocks like "Task 9: some text"
    tasks = []
    for t in matches:
        cleaned = t.strip().replace("\n", " ").strip(" .")
        if cleaned:
            tasks.append({
                "instruction": cleaned,
                "source": "gpt-4o-mini",
            })
    return tasks

##
def create_task(model:str="gpt-4o-mini") -> list[dict]:
    """
    Wrapper of entire pipeline for step 1. 
    Outputs nice list[dict] with keys instruction and source.
    To use in loop to fill data/generated_task.jsonl
    """
    sample_list = grab_subsample()
    prompt = create_prompt(sample_list)
    generated_instructions_str = generate_instructions(prompt, model=model)
    task_list = parse_instructions(generated_instructions_str)
    return task_list

if __name__ == '__main__':
    task_list = create_task()
    print(f"Dict : {task_list}")
    print("\n")
    for i in range(len(task_list)):
        print(task_list[i]['instruction'])
</code></pre>
    </section>


    <footer class="small" style="margin-top:28px; color:var(--muted)">
        <p>Includes data adapted from <em>SELF-INSTRUCT</em> (Wang et al., 2023), licensed under Apache-2.0.</p>
      </footer>
    </main>
  </body>
  </html>